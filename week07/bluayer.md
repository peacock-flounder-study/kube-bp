# Chapter 14. 쿠버네티스에서 머신러닝 실행하기

https://openai.com/index/scaling-kubernetes-to-7500-nodes/

## ML에 k8s를 사용하면 좋은 점
- 보편성
- 스케일링
- 확장성
- 셀프 서비스
- 이식성

## 쿠버네티스 클러스터 관리자가 고려해야 할 사항

### 모델 훈련

CPU, GPU -> 리소스를 더 많이 투입할수록 훈련도 더 빨리 끝난다.

### 분산 훈련

걸음마 단계라 최적화하기 어려우며, GPU 4개 장착된 서버 2대보다 GPU 8개 달린 서버 1대에서 훈련하는 편이 거의 항상 더 빠르다.

### 특수 하드웨어

쿠버네티스는 디바이스 플러그인을 통해 GPU에 액세스 할 수 있으므로 GPU 리소스도 스케줄링할 수 있다.

일반적으로 데몬셋으로 실행

**특이성 스케줄링**

k8s는 자신이 모르는 리소스에 대해서는 어떤 결정도 내리지 않는다. 

### 라이브러리, 드라이버, 커널 모듈

전용 라이브러리, 드라이버, 커널 모듈을 통해 특수 하드웨어에 액세스 한다.

특수 하드웨어에 액세스하려면 : 특권 컨테이너가 필요할 수도 있다.

### 스토리지

- 훈련 중 데이터셋 스토리지와 워커 노드 간의 분산 : 수백MB ~ GB는 블록 스토리지가 적합. 수십 수백 TB는 오브젝트 스토리지
- 체크포인트 및 저장 모델 : RW Many가 지원되는 PV를 씀

### 네트워킹

네트워크 대역폭이 몹시 높아야 하면 인피니밴드를 검토하자.

커널에서 유선 네트워크를 통해 데이터를 전송하는 부분이 문제인 경우도 있음 -> RDMA를 사용

### 전용 프로토콜

분산 훈련 스케일링 문제를 해결 -> 여러 노드에 있는 GPU가 직접 정보를 주고 받는다

- MPI
- NCCL

## k8s 머신러닝 모범 사례

- 스마트 스케줄링, 오토 스케일링 : 대부분의 단계가 배치 처리이기 때문에 GPU를 사용하게 만들기 항상.
- 모델 훈련의 균형 : 한 영역에서 뭔가 빠르게 움직이면 다른 영역에서 병목이 생길 가능성이 높다.
- 혼합 워크로드 클러스터 : 머신러닝 노드 풀
- 분산 훈련 : 하드웨어를 추가로 꽂는 것처럼 단순한 문제가 아님.

# Chapter 15. 고수준 애플리케이션 패턴 구축

구성/배포하는 방식을 표준화함으로써 모든 직원들이 동일한 운영 모범 사례를 따르게 할 수 있다.

## 고수준 추상화 개발 방식

- 쿠버네티스를 일종의 구현 상세로 래핑
- 쿠버네티스 자체에 확장 기능을 내장시켜 사용.

추상화 레이어의 목표에 따라 두 방식 중 선택.
사용 편의성이 중요 -> 완전 격리된 통합 환경을 구축하는 첫 번째 방법 (머신러닝)

자바 애플리케이션 쉽게 배포하기라면 래핑보다 확장 방식이 낫다. 1. 애플리케이션 개발은 범위가 매우 넓으며, 2/ 쿠버네티스의 기존 툴 체계를 활용하는 것이 효과적

## 쿠버네티스 확장

### 쿠버네티스 클러스터 호가장

1. 사이드카 : 어드미션 컨트롤러를 통해 API 오브젝트의 유효성을 검사하거나 조작하거나 모든 파드에 사이드카를 자동으로 추가할 수 있다. 단, 백도어(특정 전용 애너테이션)를 열어둬야 할 수도.
2. 쿠버네티스 UX 확장
3. 컨테이너화 개발 간소화 : Draft, Skaffold, Paketo
4. Push-to-deploy 환경 구축

## 플랫폼 구축 시 설계 고려 사항

### 컨테이너 이미지로 익스포트하는 기능

개발자 입장에서는 버그를 살짝 고치거나 새로운 기능을 제공하고 싶었을 뿐인데, 갑자기 애플리케이션 패키징까지 배워야 한다면 머릿속이 아득해질 것이다.

플랫폼의 프로그래밍 환경을 제네릭한 컨테이너로 내보낼 수 있게만 지원하면, 플랫폼 유저인 개발자가 다 배울 필요는 없다.

### 기존 서비스와 서비스 디스커버리 메커니즘 지원

바퀴를 다시 발명하지 말자. 쿠버네티스 서비스, DNS를 잘 활용하자.

## BP

- 어드미션 컨트롤러를 사용하여 클러스터에 대한 API 호출을 제한하고 수정하자.
- kubectl 플러그인을 상요하자
