# Chpater 11. 클러스터 정책과 거버넌스

## 정책의 변별성

쿠버네티스에서 정책은 곳곳에 다 있다.

그런데 쿠버네티스 리소스 스펙의 필드 값은 어떤 정책으로 제한하는 걸까?

## 클라우드 네이티브 정책 엔진

다양한 요건을 충족시킬 정도로 유연한 정책 엔진이 필요하다.

OPA는 유연하면서도 가벼워 다양한 클라우드 기반 시스템에서 효과적으로 활용한다. (구현체 : GateKeeper, Kyberno)

## GateKeeper

Admission Webhook, OPA contraint framework를 사용해서 CRD 기반의 정책을 적용.

리소스를 검사하고 감사하는 기능

### 정책 예제

- 서비스가 인터넷에 노출되면 안된다.
- 신뢰할 수 있는 컨테이너 레지스트리에서 생성된 컨테이너만 허용한다.
- 모든 컨테이너에 반드시 리소스 리밋을 설정한다.
- 인그레스 호스트네임이 중복돼선 안 된다.
- 인그레스는 HTTPSㅏㄴ 사용한다.

### 용어

- constraint : 리소스 스펙의 특정 필드 및 값에 적용하는 제약
- Rego : OPA Native query lang.
- constraint template : 파라미터화된 target Rego와 타입 지정된 파라미터로 구성

### Constraint template

CRD. 

## 집행 액션과 감사 적용

- deny : 위배된 리소스 생성 X, 감사 로그에 남기고 유저에게 보냄
- warn : 생성은 됨 
- dryrun : 리소스 생성, 유저에게 안 보내며 정책에 위배된 리소스는 감사 로그에서 확인

정책을 처음 rollout할 때 리소스가 배포된 클러스터에는 어떻게 적용할지 등을 고민해야함.

### 변형

일반적으로 어드미션 시점에서 리소스를 바꾸는 행위는 모범 사례라고 볼 수 없다.

### 정책 테스팅

CI/CD로 정책을 테스트하고 평ㅎ가하는 것이 필요. gator 같은 CLI 툴

## BP
- 제약조건은 가급적 엄격하게 적용하려는 리소스로 그 범위를 한정하자.
- warn, dryrun으로 시작하기
- 시크릿처럼 민감한 데이터에 정책을 동기화하거나 적용하는 것은 좋지 않다. OPA가 캐시에 보관한 상태라면 attack vector에 노출될 가능성이 있다.

# Chapter 12. 멀티클러스터 관리

쿠버네티스는 많은 워크로드를 하나의 클러스터로 통합하기 위해 구축하는 것.

**그러나 여러 리전에 분산된 워크로드, 폭발 반경 문제, 컴플라이언스, 특수 워크로드 등** 멀티클러스터가 필요한 시나리오가 있다.

## 멀티클러스터의 중요성

고려사항
- 폭발 반경
- 컴플라이언스
- 보안
- 하드 멀티테넌시
- 리전 기반 워크로드
- 특수 워크로드

참고 : https://danveloper.medium.com/on-infrastructure-at-scale-a-cascading-failure-of-distributed-systems-7cff2a3cd2df

**대규모 쿠버네티스 클러스터에서 보안을 제대로 관리하기란 만만치 않다.**

멀티 클러스터를 사용하면 격리는 '공짜로' 할 수 있지만, 처음부터 해결해야 할 몇 가지 설계 관심사가 있다.

## 멀티클러스터 설계 문제 

- 데이터 복제
- 서비스 디스커버리 : 콘술 같은 걸 이용하면 멀티클러스터, 쿠버네티스 외부 서비스까지 동기화 가능. 링커드, 실리움, 이스티오도 가능
- 네트워크 라우팅 : 클러스터를 오가는 트래픽
- 운영 관리 : 자동화 프랙티스를 정착시켜 운영 부담을 최대한 줄이기. 인프라 배포와 클러스터 애드온 관리까지 함께 신경 써야함.
- 지속적 배포 : kubespray, kops 모든 좋지만, 반복적으로 할 수 있게 소스 제어가 가능한 툴을 사용해야 함.

## 배포와 관리 패턴

오퍼레이터를 사용하면 애플리케이션과 서비스의 배포를 클러스터 수준에서 추상화할 수 있다.

각 클러스터와 팀별로 다양한 오브젝트의 생성/관리 + 버전, 퍼시스턴트, 유지 정책 등 기본 구성 => 클러스터가 늘수록 부담

오퍼레이터를 통해 k8s API를 확장 => 새로운 카인드의 오브젝트를 통해 kubectl로 컨트롤

핵심 운영 태스크를 Operator 패턴으로 자동화하면 클러스터 관리 역량을 전반적으로 끌어올릴 수 있다.

근본 개념은
- CRD
- Custom controller : 네임스페이스, 디플로이먼트, 파드, CRD 등의 k8s API object에서 이벤트를 관찰하는 로직을 직접 구축할 수 있다.

## 깃옵스로 클러스터를 관리하는 방식

깃헙 리포지토리와 쿠버네티스 클러스터 상태를 동기화하기 쉽다.

## 멀티클러스터 관리 툴

여러 클러스터 작업할 때 kubectl을 사용하면 클러스터마다 컨텍스트를 따로 관리해야해서 헷갈림.

kubectx, kubens가 꼭 필요. 혹은 Rancher, OCM, Gardener.

## BP

- 폭발 반경을 제어하자
- 애플리케이션에 여러 리전이 필요한 경우, Global Server Load Balancer, GSLB를 활용하여 클러스터 간 트래픽을 관리하자
- 오퍼레이터 활용을 통해 운영 태스크를 자동화하자
- 서비스 디스커버리, 네트워킹 구축을 고민하자
- 모든 환경에 깃옵스가 적합한 것은 아니지만, 적어도 멀티클러스터 환경의 운영 부담을 줄이는 차원에서 미리 검토하자.

# Chapter 13. 외부 서비스와 쿠버네티스 통합

신규 애플리케이션을 기존 애플리케이션과 어떻게 통합할 것인가?

## 쿠버네티스로 서비스 임포트

- 네트워킹 정상화
- 외부 서비스가 처음부터 쿠버네티스 서비스였던 것처럼 보이게 만들기 => 이걸 알아보자

### selector-less 서비스로 안정적인 IP 주소 사용

외부 리소스의 특정 IP 주소와 엔드포인트가 일치하도록 프로그래밍

### CNAME 기반 서비스로 안정적인 DNS 네임 사용

외부서비스가 안정적인 IP 주소가 아니라 안정적인 DNS 네임을 가지고 있을 때.

CNAME을 로컬 DNS 이름으로 바꿔서 매핑하는 작업

### 액티브 컨트롤러 방식

엔드포인트 리소스를 올바르게 생성하고 정보를 채워 넣으려면 제어 루프가 필요하다.

인프라를 다이내믹하게 쿼리한 다음 이 IP 주소로 서비스의 엔드포인트를 채운다. k8s에서는 DNS 서버와 kube-proxy를 프로그래밍하여 외부 서비스로 트래픽을 올바르게 로드 밸런싱하면 된다.

## 쿠버네티스에서 서비스 익스포트

반대로 쿠버네티스에 있는 서비스를 기존 환경으로 익스포트 해야 할 때라면.

**기존 애플리케이션과 쿠버네티스 파드 사이의 라우팅을 설정하는 부분이 핵심이다**

### 내부 LB로 서비스 익스포트

내부 LB를 거쳐 서비스를 익스포트 하면 외부에서 라우팅 가능한 안정적인 IP 주소 확보가 가능

### NodePort

온프렘 환경에서는 사용할 수 없으니, NodePort로 익스포트해서 서비스로의 포워딩을 하자. 

### 외부 서버와 통합

여기까지 안 됐다면, 애플리케이션을 실행하는 머신을 k8s 클러스터 SD와 네트워킹 메커니즘에 직접 통합...해야 한다.

소속될 머신에서 kubelet은 실행하되, 스케줄링 기능은 비활성화하자. + kube-proxy를 통해 머신 수준 네트워킹 설정을 하자. => 이걸 하느니 차라리 이 클러스터를 가져오는게 쉬울 수도 있다.

## 쿠버네티스 간 서비스 공유

클러스터 데몬을 만들어서 양 클러스터에서 각각 실행하자. 멀티클러스터 서비스 API를 정의하는 작업 => https://github.com/kubernetes-sigs/mcs-api

## 서드파티 툴

서비스 메시 기술을 신중하게 검토해보자.
