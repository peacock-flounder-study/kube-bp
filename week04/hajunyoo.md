# **전 세계 애플리케이션 배포 및 스테이징**

훌륭한 서비스가 성공을 거두면 전 세계 사용자들이 이용하기 시작. 

이때 사용자가 어디에 있든 최고의 경험을 제공하기 위해 애플리케이션을 전 세계 데이터 센터에 '지점'처럼 설치하고 운영해야 할 필요성이 생김 (로컬리티)

### **글로벌 배포의 3가지 핵심 동기**

애플리케이션을 전 세계에 배포해야 하는 이유는 크게 세 가지로 요약 가능

- **확장성 (Scalability):** 애플리케이션이 엄청난 성공을 거두어 수많은 사용자를 감당해야 할 때, 한 지역의 서버만으로는 부족. 전 세계 여러 곳으로 부하를 분산시켜야 안정적인 서비스 제공이 가능 (예: 전 세계 사용자를 대상으로 하는 소셜 네트워크).
- **지연 시간 (Latency):** 사용자와 서버의 물리적 거리가 멀수록 데이터가 오가는 데 시간이 오래 걸려 서비스가 느리게 느껴짐. 사용자와 가장 가까운 곳에 서버를 두면 빛의 속도 한계에 따른 지연을 최소화하여 훨씬 빠른 경험을 제공할 수 있음.
- **지역성 (Locality):** 특정 국가의 데이터 개인정보 보호법을 준수하거나 대용량 데이터 처리 비용을 줄이기 위해 특정 지역에 애플리케이션을 반드시 배치해야 하는 경우 
(예: 유럽의 GDPR과 같은 데이터 보호법 준수 또는 원격 탐사 데이터 처리 시의 네트워크 비용 절감).

### **2. 글로벌 배포의 3가지 기술적 과제**

> **과제 1: 이미지 배포**
> 

글로벌 애플리케이션 운영의 핵심 과제인 이미지 배포는 **전 세계 클러스터에서 애플리케이션 이미지를 사용 가능하게** 만들어 빠르고 안정적인 롤아웃을 보장하는 것이 목표

**권장 방식: 자동 지리적 복제 활용**

가장 먼저 고려해야 할 사항은 이미지 레지스트리에 **자동 지리적 복제(automatic geo-replication) 기능**이 있는지 여부

- **작동 방식:** Cloud 제공업체 레지스트리(예: Microsoft Azure 컨테이너 레지스트리)는 이미지를 전 세계에 자동으로 배포하며, 이미지를 가져오는 클러스터에서 **가장 가까운 스토리지 위치**로 요청을 해결.
- **간단한 관리:** 이미지를 푸시하고 지역을 선택하면 레지스트리가 복제를 처리
- **일관성:** 지리적 배포는 **자동화된 릴리스 파이프라인의 일부**가 되어야 일관성을 보장할 수 있음

**자동 복제 미지원 시 고려 사항**

Cloud 레지스트리를 사용하지 않거나 자동 복제를 지원하지 않는 경우, 직접 해결해야 함

**A. 단일 레지스트리 사용의 위험:**

단일 지역에 레지스트리를 둘 경우, 다음과 같은 우려 사항이 발생

1. **높은 지연 시간:** 컨테이너 시작 속도와 머신 장애 대응 속도를 저하시킴
2. **단일 장애 지점 (SPOF):** 레지스트리가 오프라인 상태가 되면 CI/CD 파이프라인이 중단됨
3. **대역폭 비용 증가:** 새 컨테이너를 시작할 때마다 상당한 대역폭이 소모됨

**B. 직접 복제 솔루션 (두 가지 옵션):**

이미지를 복제해야 하는 경우, 다음 두 가지 옵션을 고려할 수 있음

1. **지리적 이름 사용 (리전 서버 접근 방식):**
    - 각 레지스트리에 고유한 지리적 이름(예: `us.my-registry.io`, `eu.my-registry.io`)을 지정
    - **장점:** 설정 및 관리가 간단하며 각 레지스트리가 독립적.
    - **단점:** 가장 가까운 이미지를 가져오기 위해 **클러스터별 구성이 필요**.
2. **네트워킹 구성 사용 (단일 DNS 엔드포인트):**
    - 모든 레지스트리가 단일 DNS 엔드포인트(예: `my-registry.io`)를 지정하도록 설정하고, 지리 인식 DNS (GeoDNS) 또는 멀티캐스트 IP를 사용하여 가장 가까운 서버로 트래픽을 라우팅
    - **주의:** 이 네트워킹 구성은 **올바르게 구현하기 까다로움**

**최종 권장 사항**

- 가장 좋은 방법은 온프레미스 서버를 사용하더라도 **Cloud 기반 레지스트리를 사용하는 것**
- 자체 레지스트리를 실행해야 하고 복제된 서비스에 대한 네트워크 경험이 부족하다면, 리전 서버 접근 방식(지리적 이름 사용)을 권장

> **과제 2: 배포 파라미터화**
> 

배포 매개변수화(Deployment Parameterization)는 전 세계 규모로 애플리케이션을 배포하고 관리하기 위한 핵심 단계이며, 여러 글로벌 위치에 맞게 배포를 조정하는 것을 목표

- **목적:** 이미지를 전 세계에 복제한 후, **여러 글로벌 위치에 맞게 배포를 매개변수화**해야 함
- **배경:** 다양한 지역에 배포할 때마다 해당 지역의 **애플리케이션 구성에 차이가 있을 수밖에 없기** 때문
- **예시:** 지역 복제 레지스트리가 없는 경우, 지역마다 **이미지 이름을 조정**해야 할 수도 있음

구현 접근 방식

- **비권장 방식:** 각 글로벌 리전마다 다른 디렉터리를 사용하며 동일한 구성을 단순히 복사하는 것은 권장되지 않음. 이는 일부 지역의 수정 사항이 누락되어 구성 간의 일관성이 깨질 수 있기 때문.
- **권장 방식 (템플릿 기반):**
    - **템플릿 기반 접근 방식**을 사용해야 함
    - 대부분의 구성을 모든 리전에서 공유하는 **단일 템플릿**에 유지하고,
    - 이 템플릿에 **매개변수를 적용**하여 리전별 템플릿을 생성

**사용 도구**

- 이러한 종류의 템플릿을 만드는 데 일반적으로 사용되는 도구는 헬름(Helm)

> **과제 3: 글로벌 트래픽 분산**
> 

애플리케이션이 전 세계에서 실행 중이므로 다음 단계는 애플리케이션으로 트래픽을 유도하는 방법을 결정하는 것

이 '안내' 역할은 주로 두 가지 기술이 담당

- **DNS 기반 부하 분산:** 사용자의 위치와 각 서버의 상태를 고려하여, 도메인 주소에 대한 최적의 서버 IP 주소를 알려주는 방식
- **멀티캐스트 IP:** 전 세계 모든 서버가 단 하나의 동일한 IP 주소를 공유하는 독특한 방식. 인터넷의 핵심 라우팅 기능이 자동으로 사용자의 요청을 가장 가까운 물리적 서버로 보내줌

### **3.** 글로벌 롤아웃

새로운 소프트웨어 버전을 전 세계 모든 서버에 동시에 배포하는 것은 매우 위험. 
작은 버그 하나가 전 세계 모든 사용자에게 즉시 영향을 미치는 재앙이 될 수 있기 때문. 

따라서 점진적이고 신중한 접근이 반드시 필요

**1단계: 롤아웃 전 검증**

글로벌 롤아웃의 목표는 **가능한 한 빨리 소프트웨어를 배포하는 동시에, 많은 사용자에게 영향을 미치기 전에 문제를 신속하게 감지**하는 것

1. **전체 통합 테스트:** 실제 트래픽 없이 애플리케이션의 전체 스택을 조립하여 검증. 프로덕션 데이터와 동일한 크기와 규모의 데이터 사본을 포함해야 하며, 테스트 자동화가 필수적
2. **부하 테스트:** 실제 사용자들이 몰려들었을 때도 시스템이 버틸 수 있는지, 성능 저하는 없는지 확인하는 스트레스 테스트.  실제 프로덕션 시스템의 트래픽 로그를 재생하는 것이 효과적일 수 있음
    1. 초당 요청 수, 요청 지연 시간 (평균뿐만 아니라 90번째 및 99번째와 같은 백분위수)을 측정. 또한 CPU, 메모리, 네트워크, 디스크와 같은 **리소스 사용량**의 큰 변화를 파악해야함
    2. 평균값은 소수 사용자의 극심한 지연 문제를 감춰버릴 수 있는데, 단 1%의 사용자가 겪는 끔찍한 경험이 제품 전체의 평판을 좌우할 수 있기 때문.

**2단계: 점진적 롤아웃 전략**

테스트를 통과했더라도, 실제 환경에서는 예측하지 못한 문제가 발생할 수 있음. 
따라서 다음과 같은 단계적 전략으로 위험을 최소화하며 배포를 진행.

A. 카나리아 리전 (Canary Region)

- **첫 번째 단계:** 특정 버전의 소프트웨어를 전 세계에 배포하기 전, 릴리스를 검증하려는 사람과 팀으로부터 실제 트래픽을 수신하는 **카나리아 리전**에서 시작
- **목표:** 초기 피드백을 얻고, 통합 및 부하 테스트에서 놓쳤을 수 있는 버그를 포착
- **운영:** 카나리아는 모니터링, 규모, 기능 등 모든 측면에서 프로덕션 지역처럼 취급되어야…
- **대기 시간:** 광범위한 고객이 액세스할 수 있도록 며칠 동안 릴리스를 카나리아 지역에 남겨두는 것이 좋음

B. 지역 특성 파악 및 순차적 롤아웃

- **지역 특성 파악:** 각 지역의 서로 다른 특성(예: 모바일 트래픽 비율, 입력 언어/유니코드 문자)을 고려해야 하며, 이는 인시던트의 원인이 될 수 있다고 함. 중요하다고 생각되는 다양한 특성을 표로 작성하여 롤아웃 계획에 활용
- **순서 결정:** 프로덕션 중단의 영향을 최소화하기 위해 **사용자 트래픽이 적은 지역**부터 먼저 롤아웃을 시작하는 것이 좋음
- **대기 및 모니터링:** 첫 번째 프로덕션 지역에 성공적으로 롤아웃한 후에는, 릴리스가 완료된 후 모니터링에서 문제의 징후(예: 메모리 유출)가 명확하게 식별될 때까지 충분히 기다려야 함
    - 과거 장애 발생까지 걸린 시간을 바탕으로 **지역 출시 사이의 대기 시간**을 결정 (예: 평균 장애 발생 시간의 두 배).
- **트래픽이 많은 지역:** 트래픽이 적은 비슷한 지역에 성공적으로 롤아웃한 후에는, **트래픽이 많은 지역**으로 롤아웃하여 애플리케이션의 확장 기능을 테스트
- **가속화:** 릴리스에 대한 입력 또는 부하에 큰 변화가 있는 단일 지역에만 롤아웃하는 것이 중요하며, 애플리케이션에 대한 **모든 잠재적 변수를 테스트했다고 확신한 후**에 릴리스 속도를 높이기 위해 병렬화를 시작할 수 있음

### **4. 예상치 못한 문제에 대비하기**

실제로 문제가 발생하면 스트레스가 심한 상황에서 뇌는 상당한 스트레스를 받아 가장 간단한 프로세스조차 기억하기 어려움

A. 사고 대응 준비

- **체크리스트 작성:** 복구 프로세스의 모든 필수 작업을 **올바른 순서대로 정리한 명확한 체크리스트**를 작성해야 함. 아무리 뻔해 보이는 단계라도 빠짐없이 기록해야 함
- **문서화 및 연습:** 발생할 수 있는 문제나 롤백과 같은 프로세스에 대한 대응 방법을 **문서화하고 정기적으로 연습**
- **자동화:** 사람이 명령을 잘라내어 붙여넣는 실수를 방지하기 위해 **자동화**를 추가

B. 초기 대응 및 연습 (출혈 막기)

- **가장 이상적인 초기 대응:** 사용자 트래픽을 **영향을 받은 지역에서 시스템이 정상적으로 작동하는 지역으로 이동**시켜 '출혈을 막는 것'
- **트래픽 이동 연습:** 트래픽을 해당 지역에서 다른 지역으로 성공적으로 유도할 수 있는지 여부와 소요 시간을 파악하기 위해 연습해야 함

◦ DNS 기반 부하 분산 장치를 사용하는 경우, 트래픽을 완전히 제거하는 데 **거의 하루가 걸릴 수 있다는 점**을 인지해야 함

◦ 연습을 통해 목표 달성 시간을 설정하고, 목표를 달성할 수 있을 때까지 아키텍처를 변경하고 자동화를 추가하며 계속 연습해야 함

- **전체 복구 연습:** 전체 데이터 복구 및 시스템을 이전 버전으로 전체 롤백하는 연습을 수행하고 소요 시간에 대한 목표를 설정해야 함

----------------------------------
# **Kubernetes 리소스 관리 및 최적화**를 위한 모범 사례

### **Kubernetes 스케줄러**

스케줄러는 컨트롤 플레인의 주요 구성 요소이며, 클러스터 제약 조건과 사용자 지정 제약 조건을 기반으로 리소스를 최적화하여 파드에 대한 배치 결정을 내림

스케줄러는 술어(Predicates)와 우선순위(Priorities)를 기반으로 하는 스코어링 알고리즘을 사용

**Predicates**

술어 함수는 파드를 스케줄링할 수 있는 노드를 결정하는 첫 번째 함수이며, **참 또는 거짓 값**을 반환하는 하드 제약 조건을 의미. 

예를 들어, 파드가 요청한 메모리를 노드가 충족할 수 없거나 노드가 스케줄 불가능으로 설정된 경우 해당 노드는 거짓 값을 반환하고 실행 가능한 노드 목록에서 제거됨

스케줄러가 확인하는 술어의 예시

- `PodFitsResourcesPred` (리소스 적합성)
- `MatchNodeSelectorPred` (노드 선택기 일치)
- `PodToleratesNodeTaintsPred` (테인트 허용 오차)
- `MatchInterPodAffinityPred` (파드 간 선호도 일치)

**우선순위 (Priorities)**

술어가 유효하지 않은 노드를 해제하는 반면, 우선순위 값은 모든 유효한 노드의 **상대적인 순위**를 매김. 점수가 합산된 후 최종 점수가 노드에 부여되어 우선순위를 나타냄

- 우선순위 예시: `MostRequestedPriority`, `LeastRequestedPriority`, `BalancedResourceAllocation`, `NodeAffinityPriority`, `ImageLocalityPriority` 등

### 고급 스케줄링 기법

Kubernetes는 파드를 최적으로 스케줄링하지만, 더 많은 유연성을 제공하기 위해 고급 스케줄링 기술을 사용할 수 있음. 이는 가용성 영역에 걸쳐 파드를 예약하거나 성능 이점을 위해 특정 호스트에 파드를 코로케이션(co-location)하는 데 사용됨

**파드 선호도 및 안티 선호도**

이 규칙을 사용하면 다른 파드를 기준으로 파드를 배치하는 규칙을 설정하여 스케줄링 동작을 수정하고 배치 결정을 재정의할 수 있음

- **선호도 방지 (Anti-Affinity):**
    - 레플리카셋의 파드를 여러 데이터센터 영역에 분산시켜 노드 장애가 발생하더라도 애플리케이션의 가용성을 높일 수 있음.
    - 키/값 쌍과 `topologyKey`를 활용하여 스케줄러가 단일 노드에 복제본을 코로케이션하지 않도록 보장

**Node Selectors**

특정 노드에 파드를 스케줄링하는 **가장 쉬운 방법**. 키/값 쌍의 레이블 셀렉터를 사용하여 스케줄링 결정. 예를 들어, `disktype: ssd` 레이블이 지정된 노드에만 파드를 스케줄링 가능

- 테인트(Taint)와 달리, 노드 선택기는 GPU 지원 노드를 **요청**하는 데 사용됨

**Taints and Tolerations**

테인트는 **노드에서 파드가 스케줄링되는 것을 거부**하는 데 사용. 

테인트는 Toleration과 함께 작동하여 테인트된 노드에서 파드가 스케줄링될 수 있도록 재정의 가능

- **주요 사용 사례:** 특수 노드 하드웨어 전용 노드, 리소스 예약, 성능 저하 노드 방지.
- **테인트 유형:**
    - **`NoSchedule`:** 노드에서 스케줄링을 방지하는 하드 테인트.
    - **`PreferNoSchedule`:** 다른 노드에 스케줄링할 수 없을 때만 스케줄링하도록 선호하지 않음을 나타냄
    - **`NoExecute`:** 노드에서 이미 실행 중인 파드를 퇴출(evict)
- **테인트 기반 퇴출 (Taint-based Eviction):** 노드가 건강하지 않은 경우(예: 디스크 드라이브 불량), 호스트의 파드를 클러스터의 다른 건강한 노드로 스케줄을 재조정

### 파드 리소스 관리

파드 리소스 관리는 CPU와 메모리를 관리하여 클러스터의 전체 사용률을 최적화하는 가장 중요한 측면 중 하나. 이는 컨테이너 수준 및 네임스페이스 수준에서 관리될 수 있음

**Resource Requests**

- 컨테이너가 스케줄링되기 위해 **최소한 필요**한 CPU 또는 메모리 양을 정의.
- 요청된 리소스를 충족할 수 있는 노드가 없으면 파드는 **보류(Pending) 상태가 됨**

**Resource Limits)및 파드 서비스 품질 (QoS)**

- 파드에 제공되는 **최대** CPU 또는 메모리를 정의
    - **CPU 제한:** 제한을 초과하면 컨테이너가 스로틀(throttle)됨
    - **메모리 제한:** 제한에 도달하면 파드가 다시 시작됨

컨테이너에 제한을 지정하는 것은 애플리케이션이 공정한 리소스를 할당받도록 보장하는 모범 사례. 

파드가 생성되면 다음 세 가지 서비스 품질(QoS) 클래스 중 하나가 할당

1. **Guaranteed:** CPU와 메모리의 요청과 제한이 **모두 일치**할 때 할당. 
    1. (참고: 여러 컨테이너가 있는 경우 모든 컨테이너에 요청 및 제한이 설정되어야 함).
2. **Burstable:** 제한이 요청보다 높게 설정된 경우. 요청은 보장되지만 제한까지 버스트(burst)할 수 있다고…
3. **Best Effort:** 파드의 컨테이너에 요청이나 제한이 설정되지 않은 경우 할당됨

**파드 중단 예산 (Pod Disruption Budgets - PDB)**

- Kubernetes가 호스트에서 파드를 **자발적 중단(Voluntary Disruption)**(예: 유지보수를 위한 노드 배출)을 통해 퇴출해야 할 때 애플리케이션의 가동 시간을 최소화하기 위해 설정
- **정책 설정:**
    - 자발적 퇴출 이벤트 동안 사용할 수 있는 **최소 사용 가능(`minAvailable`)** 파드 수에 대한 정책
    - **최대 사용 불가능(`maxUnavailable`)** 파드 수에 대한 정책

### 네임스페이스를 사용한 리소스 관리

네임스페이스는 클러스터에 배포된 리소스를 논리적으로 분리하고 **소프트 멀티테넌시** 기능을 제공

**네임스페이스 설계 및 모범 사례**

- 여러 팀이 단일 클러스터를 사용하는 경우 **각 팀에 네임스페이스를 할당**하는 것이 일반적
- 클러스터가 한 팀에 전용인 경우 **각 서비스에 네임스페이스를 할당**하는 것이 좋음
- **`default` 네임스페이스 사용을 권장하지 않음**. 사용자가 리소스 제약 조건을 설정할 의무가 없어 리소스 경합을 유발할 수 있기 때문
- `kube-system` 네임스페이스는 Kubernetes 내부 구성 요소에 사용되므로 애플리케이션에 사용하지 않아야 함

**리소스 할당량 (ResourceQuota)**

여러 팀이나 애플리케이션이 단일 클러스터를 공유하는 경우 중요

**논리적 단위로 클러스터를 분할**하여 단일 네임스페이스가 할당된 리소스를 초과하여 사용할 수 없도록 함

- **할당량 설정 가능 리소스:** CPU 요청 및 제한 (`requests.cpu`, `limits.cpu`), 메모리 요청 및 제한 (`requests.memory`, `limits.memory`), 스토리지 리소스, 그리고 객체 수(`count/pvc`, `count/deployments` 등)에 할당량을 설정 가능
- 설정된 할당량을 초과하는 배포는 서버에서 거부됨 (`Error from server (Forbidden)`).

**제한 범위 (Limit Ranges)**

파드 사양에서 `request`나 `limits` 설정을 잊어버린 경우, Kubernetes가 자동으로 이를 설정할 수 있도록 제공하는 어드미션 컨트롤러

- `LimitRange`는 기본 한도(`default`**)** 및 기본 요청(`defaultRequest`)을 컨테이너 수준에 적용.
- `ResourceQuota`를 사용할 때 사양에 요청이나 제한이 설정되어 있지 않으면 배포가 거부될 수 있으므로 `LimitRange`를 함께 사용하는 것이 중요

### 클러스터 및 애플리케이션 확장

**클러스터 확장 (Cluster Scaling)**

클러스터를 배포할 때 인스턴스 크기를 결정해야 하며, 이는 과학이라기보다는 예술(테크닉)에 가까움…

- **노드 풀 (Node Pools)**
    - 단일 클러스터 내에서 CPU 중심 워크로드와 메모리 중심 워크로드를 혼합하는 등, 여러 인스턴스 유형을 혼합할 때 유용
- **클러스터 자동 확장 (Cluster Autoscaler - CA)**
    - 클러스터에 사용할 수 있는 최소 및 최대 노드 수를 설정할 수 있는 애드온
    - **확장 기준:** 파드가 **보류(Pending) 상태**일 때(리소스 부족으로 인해) 스케일 결정을 내림
    - **단점:** 파드가 보류 상태가 된 후에야 새 노드가 추가되므로, 워크로드가 새 노드가 스케줄링될 때까지 기다려야 할 수 있음

**애플리케이션 확장 (Application Scaling)**

- **수동 확장:** 배포 내에서 `replicas` 수를 수동으로 변경 (정적인 워크로드에 적합).
- **수평 파드 오토스케일러 (Horizontal Pod Autoscaler - HPA):** 워크로드를 자동으로 확장.
    - **확장 기준:** Metrics Server를 통해 가져온 CPU, 메모리 또는 사용자 정의 메트릭을 기반
    - **구성:** 최소 및 최대 파드 수를 설정 (무한 확장 방지).
    - **사용자 지정 메트릭:** Metrics Server API와 메트릭 aggregator를 사용하여 외부 스토리지 대기열(큐) 등 애플리케이션별 메트릭을 기반으로 확장할 수 있음 - keda 같은
- **수직형 파드 오토스케일러 (Vertical Pod Autoscaler - VPA):** HPA와 달리 **레플리카를 스케일링하는 것이 아니라 요청(`requests`)을 자동으로 스케일링**
    - **사용 사례:** MySQL 데이터베이스와 같이 아키텍처상 스케일 아웃할 수 없는 워크로드의 리소스를 자동으로 확장하는 데 효과적
    - Recommendor, Updator, Admission plugin으로 이루어짐
        - Recommendor: 현재 및 과거 리소스 소비를 모니터링하고 컨테이너의 CPU 및 메모리 요청에 대한 권장 값을 제공
        - Updater: 어떤 파드에 올바른 리소스가 설정되어 있는지 확인하고, 그렇지 않은 경우, 컨트롤러가 업데이트된 요청으로 다시 생성할 수 있도록 해당 파드를 죽임
        - Admission Plugin : 새 파드에서 올바른 리소스 요청을 설정
    - 리소스 요구 사항 구성을 자동화하여 유지 관리 비용을 줄이고, 클러스터 리소스 활용도를 개선하는 동시에 메모리 부족 위험을 최소화

### 리소스 관리 모범 사례

- **고가용성 보장:** 파드 안티-친화성을 활용하여 워크로드를 여러 가용성 영역에 분산
- **특수 노드 예약:** GPU 지원 노드와 같은 특수 하드웨어를 사용하는 경우 **테인트**를 활용하여 필요한 워크로드만 해당 노드에 예약되도록 해야 함
- **노드 선택:** 특수 하드웨어에 파드를 예약하려면 파드 사양에 `nodeSelectors`를 적용
- **리소스 설정:** 클러스터에 배포된 모든 파드에 대해 **메모리 및 CPU 제한**을 설정
- **멀티테넌시:** `ResourceQuota`를 활용하여 여러 팀 또는 애플리케이션이 리소스를 효율적으로 공유할 수 있도록 해야함
- **클러스터 확장:** 워크로드 프로필을 이해할 때까지 **수동 클러스터 확장**으로 시작하는 것이 좋음
- **HPA 활용:** 가변적이고 사용량이 급증하는 워크로드에는 HPA를 사용