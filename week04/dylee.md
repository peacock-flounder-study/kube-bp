# 7. 글로벌 애플리케이션 분산과 스테이징
## 1. 이미지 분산 배포

- 이미지 레지스트리 자동 지리 복제 기능으로 애플리케이션 이미지를  전 세계에 위치한 클러스터에서 사용 가능 하도록 할 수 있음
- 하지만 해당 기능이 없다면 이미지 풀 레이턴시, 단일 장애점을 고려해서 이미지 배포 전략을 짜야 함
    - 각 이미지 레지스트리에 지리 명칭 부여 하거나, 네트워킹 구성을 통해 특정 리포지토리에 접속해서 이미지를 가져오는 방식으로 활용 가능 하지만, 클라우드 기반의 레지스트리를 사용하는 것을 권장

## 2. 배포 파라미터화

- helm기반으로 템플릿을 파라미터화 하여 리전별 템플릿을 만들어서 각 리전마다 애플리케이션 구성을 다르게 하자

## 3. 글로벌 트래픽 로드 밸런싱

- 애플리케이션이 전 세계에서 서비스 되고 있다면? → 다양한 리전에 배포한 애플리케이션에 균등한 트래픽이 흐르도록 설정하자
    1. 지리 근접성을 토대로 서비스에 도달하는 레이턴시를 줄이기
    2. 여러 리전에 걸쳐 failover 
- DNS 기반 로드 밸런싱: 사용자가 도메인 주소 입력 → dns서버가 사용자의 위치를 파악하고 가장 가까운 서버의 IP 주소 반환 → IP 주소 자체가 달라짐
- 애니캐스트 라우팅: 사용자가 도메인 주소 입력 → dns 는 항상 같은 IP 주소를 반환하지만 실제 패킷 라우팅은 사용자와 가장 가까운 물리 서버로 연결

## 4. 안정적인 글로벌 롤아웃

- 글로벌하게 배포하는 방법

### 1. 사전 롤아웃 검사

- 완전한 통합 테스팅 진행하여 실제 트래픽 없이 전체 스택을 풀 스케일의 애플리케이션으로 배포 해 보기

→ 애플리케이션 개발 초기에 수행할수록 유리함(복잡성이 낮은 시점)

- 테스트 입력, 인터랙션이 주어진 상황에서 애플리케이션이 예상대로 움직이는지 확인하기
- 초당 요청 수, 요청 레이턴시 메트릭 파악하는 것이 중요(실제 유저가 느끼는 메트릭)
- 리소스 사용량(cpu, 메모리, 네트워크, 디스크)도 관찰하기

### 2. 카나리 리전

- 카나리 리전: 릴리스를 검사하려는 사람이나 팀에서 보낸 실제 트래픽을 수신하는 배포 공간, rollout시 배포 때문에 장애가 발생할 수 있음을 경고
- 리스크가 낮은 유스케이스(개발,내부유저)에는 카나리를 사용하도록 하여 릴리스에 대한 초기 피드백을 받자

### 3. 리전 타입 식별

- 리전의 특성을 파악해서 글로벌 롤아웃에 대비하자

### 4. 글로벌 롤아웃 전략 수립

- 첫 번째 프로덕션 리전에 롤아웃 후 다음 리전으로 진행하기 전 까지 기다리는 시간을 정하자

→ 기다리는 시간은 과거에 문제가 생길 때 까지 소요된 평균 시간의 2배 정도가 적절함

### 5. 문제 발생 시 대처 요령

- task에 대한 checklist를 작성하고 단계별 예상 결과를 정리하고 기록하자
- 문제가 발생하지 않았을 때 트래픽을 다른 리전으로 옮겨보고, 데이터 복구를 연습하자

# 8. 리소스 관리
## 1. 쿠버네티스 스케줄러

- control plane에 위치하여 클러스터에 배포된 파드를 어떻게 배치할지 결정하는 주요 컴포넌트 중 하나
- 스케줄러는 클러스터 제약조건과 유저가 지정한 제약 조건에 따라 리소스를 최적화함

### 1. 프레디킷

- 어느 노드에 파드를 스케줄링 할 지 결정 → 스케줄링 가능 여부에 따라 true/false 반환
- 스케줄러는 제약성과 복잡도 순서로 predicate 체크

### 2. 우선순위

- predicate이 false인 노드 → 스케줄링에서 배제
- predicate이 true 인 노드 → 상대적인 값에 따라 전체 노드의 우선순위가 매겨짐
- 우선순위 점수가 동일한 노드가 반환되는 경우 → 스케줄러는 selectHost()함수를 사용하여 라운드 로빈 방식으로 노드 선택

## 2. 고급 스케줄링 기법

- 쿠버네티스는 리소스 사용률을 균등하게 맞추기 위해 리소스에 따라 노드를 배치하고 동일한 replicaset의 pods는 여러 node에 분산시킴
- 또는 직접 리소스 스케줄링도 가능

### 1. 파드 어피니티와 안티-어피니티

- 파드 간의 상대적인 배치 규칙을 적용하여 스케줄링 방식을 변경하거나 스케줄러의 배치 결정을 오버라이드
- 사용 예시) pods의 key-label을 활용하여 replicaset에 있는 pod를 여러 리전에 분산시킴

### 2. 노드셀렉터

- key/value 로 이루어진 label selector로 node에 pod를 스케줄링
- node selector → 해당하는 node를 request
- taint → 해당 workload에 대해서만 node를 reserve
- taint와 toleration
    - taint: 해당 node에 일반적인 pod들이 스케줄링되지 않도록 함(컨테이너의 스케줄링, 실행에 영향을 줌)
    - toleration: 이 설정을 한 pod는 taint node에 스케줄링 가능
    - 특수 하드웨어가 장착된 노드, 전용 노드 리소스, 성능이 저하된 노드를 배제하기 위해 사용
- taint의 종류
    - NoSchedule: 특정 노드에 스케줄링을 차단
    - PreferNoSchedule: 다른 노드에 스케줄링 불가한 경우에만 파드를 스케줄링
    - NoExecute: 노드에 이미 실행 중인 파드가 있으면 내쫓음
    - NodeCondition: 특정 조건을 충족하는 노드를 테인트
- taint-based evection: 실행 중인 파드를 다른 노드로 리스케줄링

## 3. 파드 리소스 관리

- 애플리케이션에게 필요한 리소스를 파드 스펙에 명시하여, 파드 리소스를 적절하게 관리해 스케줄러가 리소스를 최적화하고 적절하게 배치 하도록 해야 함

### 1. 리소스 요청

- 컨테이너 스케줄링에 필요한 cpu, 메모리 값을 정의 → 만약 모든 노드가 필요한 메모리 값 보다 적은 양을 가지고 있다면 파드가 스케줄링 되지 않고 대기 상태가 됨
- kubectl top: 클러스터에서 가용한 리소스 확인

### 2. 리소스 리밋과 파드 QoS

- 파드가 사용하는 cpu, 메모리의 최댓값을 정한 것
    - cpu 리밋 초과 시 컨테이너가 cpu를 사용하지 못하게 스로틀링
    - 메모리 리밋 초과 시 파드를 재시작
- 파드 생성 시 Guaranteed, Burstable, BestEffort Qos class 중 한 개가 할당됨
    - Guaranteed: 메모리 요청 = 리밋
    - Burstable: 메모리 요청 < 리밋 → 요청은 보장하지만 리밋까지 폭주할수도..
    - BestEffort: 요청, 리밋 모두 설정 x

### 3. PodDisruptionBudgets

- 애플리케이션의 가동 시간을 보장하여 파드 축출 시 애플리케이션 영향도를 최소화
- minAvailable(최소 가용 파드 수): 가용 파드를 n개 유지하고 원하는 만큼의 pod 축출
- maxUnavailable(최대 불용 파드 수): 전체 파드의 n%까지만 축출

### 4. 네임스페이스를 이용한 리소스 관리

- namespace마다 리소스 쿼터, RBAC, 네트워크 정책 정함 → 팀 상황에 따라 ns access를 설정하자
- multitenancy기능으로 cluster에서 workload를 분리하여 cluster resource를 논리적으로 구분하여 활용 가능
- 네임스페이스 종류
    - kube-system: 쿠버네티스 내부 컴포넌트가 배포된 네임스페이스
    - default: 리소스 오브젝트에 네임스페이스 미지정 시 사용되는 디폴트 네임스페이스
    
    → kube-system, default ns는 리소스 경합이 일어날 수 있어 사용 지양하기
    
    - kube-public: 익명 또는 미인증 콘텐츠, 시스템 관리 용도로 예약된 네임스페이스.

### 5. 리소스 쿼터

- 클러스터를 논리적인 단위로 분할하여 한 네임스페이스가 cluster에서 자기 몫 이상의 리소스를 차지하지 못하게 통제 → 여러 팀이나 애플리케이션이 하나의 cluster를 사용할 때 namespace에 ResourceQuota를 부여하자!

### 6. 리밋레인지

- pod spec에 limit을 적용하지 않아도 쿼터와 리밋레인지를 설정하여 namespace에 적용하면 해당 컨테이너에 request, limit 적용 가능

### 7. 클러스터 스케일링

- 수동 스케일링
- 클러스터 오토스케일링
    - 파드가 대기 상태가 된 시점을 기준으로 클러스터에 설정된 최소 가용 노드 수, 스케일링 가능한 최대 노드 수에 따라 스케일링 여부 결정 후 스케줄링
    - 리소스가 불필요한 경우 클러스터 사이즈를 다시 줄일 수 있음 → 이때 PodDisruptionBudget을 통해 노드를 드레인하고 클러스터의 새 노드에 파드를 리스케줄링 하는 것을 권장(애플리케이션에 영향 끼치지 않도록..!)

### 8. HPA를 이용한 수평 스케일링

- HPA가 deployment를 관찰하며 metrics-server에서 메트릭을 가져와서 → 수평 스케일링
- horizontal-pod-autoscaler-sync-peroid: 메트릭 동기화 주기
- horizontal-pod-autoscaler-upscale-delay: 두 스케일-업 작업 간 대기 시간
- horizontal-pod-autoscaler-downscale-delay: 두 스케일-다운 작업 간 대기 시간

### 9. 커스텀 메트릭을 이용한 HPA

- 커스텀 메트릭 api + metric aggregator로 thrid-party provider가 plugin형태로 메트릭을 스케일링 하게 하면 hpa는 외부 메트릭을 기반으로 스케일링 → 메시지 큐 기반 스케일링, 외부 로드밸런서 메트릭 등등

### 10. 수직 하트 오토스케일러

- VPA: 쿠버네티스가 자동으로 파드를 확장/축소 → 아키텍처상 scale-out이 불가능한 workload에서 리소스를 오토스케일링하는데 효과적(ex/MySQL)
- VPA 구성 컴포넌트
    - Recommender: 현재/과거 리소스 소비를 계속 모니터링하면서 컨테이너의 cpu, 메모리 요청에 관한 권장값 제공
    - Updater: 파드에 리소스가 올바르게 설정되어 있는지 확인하고, 그렇지 않다면 업데이트된 요청으로 컨트롤러가 파드를 재생성하도록 기존 파드를 없앰
    - Admission Plugin: 새 파드에 올바른 리소스 요청 설정

## 4. 리소스 관리 모범 사례

- 파드 안티-어피니티를 설정하여 워크로드를 여러 가용 영역에 분산시키고 애플리케이션 고가용성 보장하기
- 특수 노드를 사용하는 경우 해당 노드가 필요한 워크로드만 파으데 스케줄링되도록 node에 taint 붙이기
- NodeCondition taint를 사용하여 노드 장애, 성능 저하 예방
- pod spec에 nodeselector적용하여 주어진 노드에 파드가 스케줄링 되도록 함
- 다양한 사이즈의 노드로 실험을 해보면서 비용,성능의 적절한 조합을 알아낸 다음 프로덕션 고고
- 단일 클러스터에 다양한 성능 특성을 지닌 워크로드가 혼재된 경우 노드 타입별로 노드 풀을 사용하여 구분하기
- 클러스터애 배포된 모든 파드에 cpu, memory limit 설정하기
- 리소스 쿼터 설정하여 여러 팀, 애플리케이션이 클러스터 리소스를 공평하게 할당받도록 하자
- 리밋레인지를 사용하여 요청/리밋을 설정하지 않은 파드 스펙에 디폴트 요청/리밋 값을 설정하기
- k8s의 워크로드 프로파일을 온전히 이해하기 전 까지 수동으로 클러스터 스케일링 하지
- 변동성이 큰 워크로드에는 hpa를 사용하여 예기치 않은 부하 폭주를 예방하자
